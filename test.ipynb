{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "# Load HTML, gpt researcher\n",
    "url = \"https://klientboost.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content with LLM\n",
      "The easiest, fastest and most efficient way to A/B test. Insert your URL below and start testing now. Thanks to the use of GPT-3, we offer automated text suggestions for your headline, copy and Call To Action. Save time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hero_header': 'The easiest, fastest and most efficient way to A/B test.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "import os\n",
    "import asyncio\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncHtmlLoader, AsyncChromiumLoader\n",
    "from langchain.document_transformers import BeautifulSoupTransformer\n",
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "async def scrape_with_playwright(urls, schema):\n",
    "    loader = AsyncHtmlLoader(urls)\n",
    "    docs = loader.load()  # Make sure to use await for an async function\n",
    "    \n",
    "    bs_transformer = BeautifulSoupTransformer()\n",
    "    docs_transformed = bs_transformer.transform_documents(docs)\n",
    "    print(\"Extracting content with LLM\")\n",
    "\n",
    "    # Grab the first 1000 tokens of the site\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=50, chunk_overlap=0)\n",
    "    splits = splitter.split_documents(docs_transformed)\n",
    "\n",
    "    print(splits[0].page_content)\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    chain = create_extraction_chain(schema=schema, llm=llm)\n",
    "    #extracted_content = chain.run(splits[0].page_content)\n",
    "    #get only most probable answer\n",
    "    extracted_content = chain.run(splits[0].page_content)[0]\n",
    "    return extracted_content\n",
    "\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"hero_header\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"hero_header\"],\n",
    "}\n",
    "\n",
    "# Define your URLs here\n",
    "urls = [\"https://abtesting.ai/\"]\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# Run the async function within the Jupyter event loop\n",
    "await scrape_with_playwright(urls, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Font Size not found - The Performance Marketing Agency\n",
      "That Doubles Revenue, Not Your Budget\n",
      "Font Size not found - Times are tough right now. Work with a marketing agency \n",
      "that drives more pipeline, revenue, and profit without sacrificing quality.\n",
      "Font Size not found - Winning marketing data from 250+ active clients, customized for you\n",
      "Font Size not found - Winning marketing data from 250+ active clients, customized for you\n",
      "Font Size not found - One Agency + Multiple Marketing Channels = \n",
      "More Money In Your Pocket\n",
      "Font Size not found - We help companies scale their strategies across multiple channels \n",
      "to drive more revenue, more quickly, without cutting corners.\n",
      "Font Size not found - Your Custom Marketing Plan Shows \n",
      "The Exact Steps We’ll Take To Hit Your Goals\n",
      "Font Size not found - Get years of data-driven experimentation, through hundreds of millions of marketing spend,\n",
      "across thousands of companies, absolutely free.\n",
      "Font Size not found - Your Marketing Will Perform Better With Us\n",
      "Font Size not found - Your custom marketing plan from us will beat your current one. Here's why...\n",
      "Font Size not found - You’ll get insider knowledge around what new marketing strategies and tactics perform best across 250+ other companies.\n",
      "Font Size not found - You’ll get help from 130+ brains for less than the price of one (we did the research on actual brain cost The Brain Market: How to Acquire Brains Both Legally and Illegally – read here, What is Your Brain Worth? – read here, How do I (legally) purchase a human brain? – read here, and Human Brain Microvascular Endothelial Cells – read here).\n",
      "Font Size not found - Better Marketing Performance Is Ready For You - Are You?\n",
      "Font Size not found - Agency\n",
      "Font Size not found - Paid Advertising\n",
      "Font Size not found - SEO\n",
      "Font Size not found - Conversion\n",
      "Font Size not found - Email Marketing\n",
      "Font Size not found - We don't bite.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers={\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\",\n",
    "        }\n",
    "url = \"https://klientboost.com/\"\n",
    "req = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "# get all p and header and text size, sort by text size and location\n",
    "elements = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\"])\n",
    "def get_font_size(element):\n",
    "    style = element.get(\"style\", \"\")\n",
    "    style_parts = style.split(\";\")\n",
    "    for part in style_parts:\n",
    "        if \"font-size\" in part:\n",
    "            size_parts = part.split(\":\")\n",
    "            if len(size_parts) == 2:\n",
    "                return float(size_parts[1].strip().replace(\"px\", \"\").replace(\"pt\", \"\"))\n",
    "    return None\n",
    "\n",
    "sorted_elements = sorted(elements, key=lambda element: get_font_size(element) or 0)\n",
    "\n",
    "# Print the sorted elements\n",
    "for element in sorted_elements:\n",
    "    font_size = get_font_size(element)\n",
    "    if font_size is not None:\n",
    "        print(f\"Font Size: {font_size} - {element.text.strip()}\")\n",
    "    else:\n",
    "        print(f\"Font Size not found - {element.text.strip()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_element(element, max_index, max_font_size, index):\n",
    "    \"\"\"\n",
    "    Score an element based on its position, type, and font size.\n",
    "    \n",
    "    Args:\n",
    "        element (Tag): The BeautifulSoup Tag representing the HTML element.\n",
    "        max_index (int): The maximum index (position) of an element in the list.\n",
    "        max_font_size (float): The maximum font size found among elements.\n",
    "\n",
    "    Returns:\n",
    "        float: The score for the element, where higher scores indicate a higher probability of being the hero header.\n",
    "    \"\"\"\n",
    "    element_type = element.name\n",
    "    font_size = get_font_size(element)\n",
    "\n",
    "    # Weight factors for scoring (you can adjust these as needed)\n",
    "    position_weight = 1.0  # Weight for element position (higher is more important)\n",
    "    type_weight = 0.5  # Weight for element type (higher is more important)\n",
    "    font_size_weight = 0.3  # Weight for font size (higher is more important)\n",
    "\n",
    "    # Calculate scores for position, type, and font size\n",
    "    position_score = 1.0 - (index / max_index)  # Higher position means lower score\n",
    "    type_score = 1.0 if element_type in [\"h1\", \"h2\", \"h3\"] else 0.0  # Headers get higher score\n",
    "    font_size_score = font_size / max_font_size if font_size is not None else 0.0\n",
    "\n",
    "    # Calculate the final score by combining weighted scores\n",
    "    final_score = (\n",
    "        (position_weight * position_score)\n",
    "        + (type_weight * type_score)\n",
    "        + (font_size_weight * font_size_score)\n",
    "    )\n",
    "\n",
    "    return final_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ram/Documents/GitHub/AB-Extension/test.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ram/Documents/GitHub/AB-Extension/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ram/Documents/GitHub/AB-Extension/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         }\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ram/Documents/GitHub/AB-Extension/test.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://buzzbonus.tech\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ram/Documents/GitHub/AB-Extension/test.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m req \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url,headers\u001b[39m=\u001b[39mheaders)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ram/Documents/GitHub/AB-Extension/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(req\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "headers={\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\",\n",
    "        }\n",
    "url = \"https://buzzbonus.tech\"\n",
    "req = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Scoring Element (Score: 1.50):\n",
      "Selector: ('h1', {'class': ['text-4xl', 'md:text-6xl', 'font-extrabold', 'text-center']}, 'SuperchargeYour Online Presence', 0)\n",
      "Text: SuperchargeYour Online Presence\n"
     ]
    }
   ],
   "source": [
    "elements = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\"])\n",
    "\n",
    "# Determine the maximum index and maximum font size among elements\n",
    "max_index = len(elements) - 1\n",
    "max_font_size = max(get_font_size(element) or 0.0 for element in elements)\n",
    "\n",
    "# Initialize variables to track the element with the highest score\n",
    "highest_score = None\n",
    "best_element = None\n",
    "best_selector = None\n",
    "\n",
    "index_elements = {\n",
    "    \"h1\": 0,\n",
    "    \"h2\": 0,\n",
    "    \"h3\": 0,\n",
    "    \"h4\": 0,\n",
    "    \"h5\": 0,\n",
    "    \"h6\": 0,\n",
    "    \"p\": 0,\n",
    "}\n",
    "\n",
    "# Score elements and find the highest-scoring element\n",
    "for index, element in enumerate(elements):\n",
    "    element_score = score_element(element, max_index, max_font_size, index)\n",
    "    \n",
    "    # Check if the current element has a higher score than the previous best\n",
    "    if highest_score is None or element_score > highest_score:\n",
    "        highest_score = element_score\n",
    "        best_element = element\n",
    "        best_selector = (best_element.name, best_element.attrs, best_element.text, index_elements[best_element.name])\n",
    "    index_elements[element.name] += 1\n",
    "\n",
    "# Print the highest-scoring element and its selector\n",
    "if best_element is not None:\n",
    "    print(f\"Highest Scoring Element (Score: {highest_score:.2f}):\")\n",
    "    print(f\"Selector: {best_selector}\")\n",
    "    print(f\"Text: {best_element.text.strip()}\")\n",
    "else:\n",
    "    print(\"No elements found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: h1, Text: The Performance Marketing Agency\n",
      "That Doubles Revenue, Not Your Budget, Font Size: None\n",
      "Type: h2, Text: Times are tough right now. Work with a marketing agency \n",
      "that drives more pipeline, revenue, and profit without sacrificing quality., Font Size: None\n",
      "Type: h3, Text: Winning marketing data from 250+ active clients, customized for you, Font Size: None\n",
      "Type: h3, Text: Winning marketing data from 250+ active clients, customized for you, Font Size: None\n",
      "Type: h2, Text: One Agency + Multiple Marketing Channels = \n",
      "More Money In Your Pocket, Font Size: None\n",
      "Type: h3, Text: We help companies scale their strategies across multiple channels \n",
      "to drive more revenue, more quickly, without cutting corners., Font Size: None\n",
      "Type: h2, Text: Your Custom Marketing Plan Shows \n",
      "The Exact Steps We’ll Take To Hit Your Goals, Font Size: None\n",
      "Type: h3, Text: Get years of data-driven experimentation, through hundreds of millions of marketing spend,\n",
      "across thousands of companies, absolutely free., Font Size: None\n",
      "Type: h2, Text: Your Marketing Will Perform Better With Us, Font Size: None\n",
      "Type: h3, Text: Your custom marketing plan from us will beat your current one. Here's why..., Font Size: None\n",
      "Type: p, Text: You’ll get insider knowledge around what new marketing strategies and tactics perform best across 250+ other companies., Font Size: None\n",
      "Type: p, Text: You’ll get help from 130+ brains for less than the price of one (we did the research on actual brain cost The Brain Market: How to Acquire Brains Both Legally and Illegally – read here, What is Your Brain Worth? – read here, How do I (legally) purchase a human brain? – read here, and Human Brain Microvascular Endothelial Cells – read here)., Font Size: None\n",
      "Type: h2, Text: Better Marketing Performance Is Ready For You - Are You?, Font Size: None\n",
      "Type: h3, Text: Agency, Font Size: None\n",
      "Type: h3, Text: Paid Advertising, Font Size: None\n",
      "Type: h3, Text: SEO, Font Size: None\n",
      "Type: h3, Text: Conversion, Font Size: None\n",
      "Type: h3, Text: Email Marketing, Font Size: None\n",
      "Type: p, Text: We don't bite., Font Size: None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL you want to scrape\n",
    "\n",
    "\n",
    "# Define user-agent headers\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Send an HTTP request to the URL and parse the HTML content\n",
    "req = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "# Find all header (h1, h2, h3, etc.) and paragraph (p) elements\n",
    "elements = soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"p\"])\n",
    "\n",
    "# Create a function to extract font size from a style attribute\n",
    "def get_font_size(element):\n",
    "    style = element.get(\"style\", \"\")\n",
    "    style_parts = style.split(\";\")\n",
    "    for part in style_parts:\n",
    "        if \"font-size\" in part:\n",
    "            size_parts = part.split(\":\")\n",
    "            if len(size_parts) == 2:\n",
    "                return float(size_parts[1].strip().replace(\"px\", \"\").replace(\"pt\", \"\"))\n",
    "    return None\n",
    "\n",
    "# Create a list to store tuples (element type, text, font size, selector)\n",
    "elements_info = []\n",
    "\n",
    "# Extract information and create tuples for header elements\n",
    "for element in elements:\n",
    "    element_type = element.name\n",
    "    text = element.text.strip()\n",
    "    font_size = get_font_size(element)\n",
    "    elements_info.append((element_type, text, font_size))\n",
    "\n",
    "# Sort the tuples by font size (in ascending order)\n",
    "# elements_info.sort(key=lambda x: x[2] if x[2] is not None else 0)\n",
    "\n",
    "\n",
    "# Print the sorted tuples\n",
    "for element_info in elements_info:\n",
    "    element_type, text, font_size = element_info\n",
    "    print(f\"Type: {element_type}, Text: {text}, Font Size: {font_size}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
